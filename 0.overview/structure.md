# Структура

Наша задача - развернуть **кластер hadoop**, содержащий **1 NameNode** и **3 DataNode**. 
Каждая Node представляет из себя отдельно работающий host (узел).

Есть несколько вариантов решения:
   -запустить у каждого члена команды по ноде и попробовать связать их через интернет;
   -найти облако, в котором запустить все указанные ноды;
   -запустить все узлы локально, используя docker-контейнеры;

Остановимся на последнем варианте, так как он самый простой и безопасный. Рассмотрим **архитектуру кластера**:

![Структура](https://github.com/aameliig/introduction_to_data_platforms_practice/blob/task1_hadoop_installation_guide/0.overview/structure_clusters.jpg)

1. Мы создадим образы:
      -**base image** - образ, в котором установлен hadoop
      -**namenode image** - образ, запускающий NameNode
      -**datanode image** - образ, запускающий DataNode

3. Создадим и настроим **конфигурационные файлы (config)** (том, volume на картинке снизу, создается после запуска контейнеров автоматически)
4. **Запуск через docker-compose** 4х контейнеров: 1 NameNode и 3 DataNode
5. **Проверим статус кластера**, убедимся, что работает корректно. **Рассмотрим веб-интерфейс** и покажем команду для подключения в консоль контейнера

Вот и весь план. Поехали!
